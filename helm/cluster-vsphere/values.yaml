# Auto-generated by helm-values-gen, do not edit!

cluster:
  internal:
    advancedConfiguration:
      controlPlane:
        apiServer:
          extraArgs:
            requestheader-allowed-names: front-proxy-client
  providerIntegration:
    apps:
      capiNodeLabeler:
        enable: true
      certExporter:
        configTemplateName: vSphereCertExporterHelmValues
        enable: true
      certManager:
        configTemplateName: vSphereCertManagerHelmValues
        enable: true
      chartOperatorExtensions:
        enable: true
      cilium:
        configTemplateName: vSphereCiliumHelmValues
        enable: true
      ciliumServiceMonitors:
        enable: true
      coreDns:
        enable: true
      etcdKubernetesResourcesCountExporter:
        enable: true
      k8sDnsNodeCache:
        enable: true
      metricsServer:
        enable: true
      netExporter:
        enable: true
      networkPolicies:
        configTemplateName: vSphereNetworkPoliciesHelmValues
        enable: true
      nodeExporter:
        configTemplateName: vSphereNodeExporterHelmValues
        enable: true
      observabilityBundle:
        enable: true
      observabilityPolicies:
        enable: true
      securityBundle:
        enable: true
      teleportKubeAgent:
        enable: true
      verticalPodAutoscaler:
        enable: true
      verticalPodAutoscalerCrd:
        enable: true
    controlPlane:
      kubeadmConfig:
        files:
          - contentFrom:
              secret:
                key: content
                name: kubevip-pod
                prependClusterNameAsPrefix: true
            path: /etc/kubernetes/manifests/kube-vip.yaml
            permissions: "0600"
      resources:
        infrastructureMachineTemplate:
          group: infrastructure.cluster.x-k8s.io
          kind: VSphereMachineTemplate
          version: v1beta1
        infrastructureMachineTemplateSpecTemplateName: controlplane-vspheremachinetemplate-spec
    environmentVariables:
      hostName: COREOS_CUSTOM_HOSTNAME
      ipv4: COREOS_CUSTOM_IPV4
    kubeadmConfig:
      enableGiantswarmUser: true
      files:
        - contentFrom:
            secret:
              key: set-hostname.sh
              name: provider-specific-files-1
              prependClusterNameAsPrefix: true
          path: /opt/bin/set-hostname.sh
          permissions: "0755"
      ignition:
        containerLinuxConfig:
          additionalConfig:
            systemd:
              units:
                - contents:
                    install:
                      wantedBy:
                        - multi-user.target
                    unit:
                      description: VMWare metadata agent
                  dropins:
                    - contents: |-
                        [Unit]
                        After=nss-lookup.target
                        After=network-online.target
                        Wants=network-online.target
                        [Service]
                        Type=oneshot
                        Restart=on-failure
                        RemainAfterExit=yes
                        Environment=OUTPUT=/run/metadata/coreos
                        ExecStart=/usr/bin/mkdir --parent /run/metadata
                        ExecStart=/usr/bin/bash -cv 'echo "COREOS_CUSTOM_HOSTNAME=$("$(find /usr/bin /usr/share/oem -name vmtoolsd -type f -executable 2>/dev/null | head -n 1)" --cmd "info-get guestinfo.metadata" | base64 -d | awk \'/local-hostname/ {print $2}\' | tr -d \'"\')" >> ${OUTPUT}'
                        ExecStart=/usr/bin/bash -cv 'echo "COREOS_CUSTOM_IPV4=$("$(find /usr/bin /usr/share/oem -name vmtoolsd -type f -executable 2>/dev/null | head -n 1)" --cmd "info-get guestinfo.ip")" >> ${OUTPUT}'
                      name: 10-coreos-metadata.conf
                  enabled: true
                  name: coreos-metadata.service
                - contents:
                    install:
                      wantedBy:
                        - multi-user.target
                    unit:
                      description: Set machine hostname
                  dropins:
                    - contents: |-
                        [Unit]
                        Requires=coreos-metadata.service
                        After=coreos-metadata.service
                        Before=teleport.service
                        [Service]
                        Type=oneshot
                        RemainAfterExit=yes
                        EnvironmentFile=/run/metadata/coreos
                        ExecStart=/opt/bin/set-hostname.sh
                      name: 10-set-hostname.conf
                  enabled: true
                  name: set-hostname.service
                - contents:
                    install:
                      wantedBy:
                        - default.target
                    unit:
                      description: Disable TCP segmentation offloading
                  dropins:
                    - contents: |-
                        [Unit]
                        After=network.target
                        [Service]
                        Type=oneshot
                        RemainAfterExit=yes
                        ExecStart=/usr/sbin/ethtool -K ens192 tx-udp_tnl-csum-segmentation off
                        ExecStart=/usr/sbin/ethtool -K ens192 tx-udp_tnl-segmentation off
                      name: 10-ethtool-segmentation.conf
                  enabled: true
                  name: ethtool-segmentation.service
      postKubeadmCommands:
        - usermod -aG root nobody
    kubernetesVersion: 1.27.14
    pauseProperties:
      global.connectivity.network.controlPlaneEndpoint.host: ""
    provider: vsphere
    resourcesApi:
      bastionResourceEnabled: false
      cleanupHelmReleaseResourcesEnabled: false
      clusterResourceEnabled: true
      controlPlaneResourceEnabled: true
      helmRepositoryResourcesEnabled: true
      infrastructureCluster:
        group: infrastructure.cluster.x-k8s.io
        kind: VSphereCluster
        version: v1beta1
      machineHealthCheckResourceEnabled: true
      machinePoolResourcesEnabled: false
      nodePoolKind: MachineDeployment
    workers:
      defaultNodePools:
        def00:
          cloneMode: linkedClone
          memoryMiB: 16896
          network: {}
          numCPUs: 6
          replicas: 2
          resourcePool: '*/Resources'
          template: flatcar-stable-3815.2.2-kube-v1.27.14-gs
global:
  connectivity:
    containerRegistries: {}
    localRegistryCache:
      enabled: false
      mirroredRegistries: []
      port: 32767
    network:
      controlPlaneEndpoint:
        ipPoolName: wc-cp-ips
        port: 6443
      loadBalancers:
        ipPoolName: svc-lb-ips
      pods:
        cidrBlocks:
          - 10.244.0.0/16
      services:
        cidrBlocks:
          - 172.31.0.0/16
    proxy: {}
    shell:
      osUsers:
        - name: giantswarm
          sudo: ALL=(ALL) NOPASSWD:ALL
      sshTrustedUserCAKeys:
        - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIM4cvZ01fLmO9cJbWUj7sfF+NhECgy+Cl0bazSrZX7sU vault-ca@vault.operations.giantswarm.io
  controlPlane:
    apiServerPort: 6443
    image:
      repository: gsoci.azurecr.io/giantswarm
    machineTemplate:
      cloneMode: linkedClone
      memoryMiB: 8192
      network: {}
      numCPUs: 4
      resourcePool: '*/Resources'
      template: flatcar-stable-3815.2.2-kube-v1.27.14-gs
    oidc: {}
    resourceRatio: 8
  metadata:
    preventDeletion: false
    servicePriority: highest
  nodePools:
    worker:
      cloneMode: linkedClone
      memoryMiB: 16896
      network: {}
      numCPUs: 6
      replicas: 2
      resourcePool: '*/Resources'
      template: flatcar-stable-3815.2.2-kube-v1.27.14-gs
  podSecurityStandards:
    enforced: true
  providerSpecific:
    defaultStorageClass:
      enabled: true
      reclaimPolicy: Delete
      storagePolicyName: ""
    vcenter: {}
internal:
  kubectlImage:
    name: giantswarm/kubectl
    registry: gsoci.azurecr.io
    tag: 1.27.14
  kubernetesVersion: v1.27.14
  sandboxContainerImage:
    name: giantswarm/pause
    registry: gsoci.azurecr.io
    tag: "3.9"
  teleport:
    enabled: true
    proxyAddr: teleport.giantswarm.io:443
    version: 14.1.3
